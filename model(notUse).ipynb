{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'INTJ':'You are thoughtful, rational, quick-witted and independent. However, sometimes you are known to be overly critical, and have a combative side to yourself.', 'INTP':'You are unique, creative, inventive and imaginative. However, sometimes you are known to be a bit insensitive and impatient with others.', 'ENTJ':'You are determined, charismatic, confident and authoritative. However, sometimes you are known to  be intolerant of other people\\'s weaknesses, and slightly arrogant.', 'ENTP':'You are audacious, bold, playful and rebellious. However, sometimes you can find it difficult to focus, and dislike talking about practical matters.', 'INFJ':'You are creative, insightful, passionate and have strong morals. However, sometimes you are a bit of a perfectionist, and find it reluctant to open up to other people.','INFP':'You are empathetic, generous, creative and passionate. However, sometimes your goals are a bit unrealistic and you tend to lack focus sometimes.', 'ENFJ':'You are passionate, reliable, charismatic and very receptive. However, sometimes you can be overly empathetic and condescending toward other people.', 'ENFP' : 'You are enthusiastic, festive, good-natured and excellent at communicating. However, you sometimes focus on being a people pleaser and disorganized.', 'ISTJ': 'You are very responsible, strong-willed, calm and enforce order. However, you are known to be stubborn and are somewhat judgemental sometimes', 'ISFJ': 'You are reliable, observant, enthusiastic and supportive. However, you are known to be overly humble and tend to take things personally', 'ESTJ' : 'You are dedicated, strong-willed, loyal and reliable. However, you find it difficult to relax, or share what you\\'re feeling with other people.', 'ESFJ': 'You are very loyal, sensitive to other people\\'s feelings, and have strong practical skills. However, you are sometimes worried about your social status and tend to be vulnerable to criticism.', 'ISTP': 'You are spotaneous, rational, optimistic and know how to prioritize things. However, you are known to be stubborn and get bored very easily.',  'ISFP' : 'You are charming, imaginative, passionate and sensitive to others. However, you are fiercely independent and get stressed out pretty easily.', 'ESTP': 'You are perceptive, direct, bold and rational. However, you tend to be defiant and may sometimes miss the bigger picture in favor of smaller victories.', 'ESFP' : 'You are observant, practical, have excellent people skills and are fond of showmanship. However, you are very sensitive and sometimes avoid conflict entirely.'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti_df = pd.read_csv(\"mbti_1.csv\")\n",
    "\n",
    "\n",
    "\n",
    "mind_names = [\"E\" , \"I\"]\n",
    "mind = []  # E or I\n",
    "\n",
    "energy_names = [\"N\",  \"S\"]\n",
    "energy = [] # N or S\n",
    "\n",
    "nature_names = [\"F\", \"T\"]\n",
    "nature = [] # F or T\n",
    "\n",
    "tactics_names = [\"J\", \"P\"]\n",
    "\n",
    "tactics = [] # J OR P\n",
    "\n",
    "for t in mbti_df.type:\n",
    "    mind.append(mind_names.index(t[0]))\n",
    "    energy.append(energy_names.index(t[1]))\n",
    "    nature.append(nature_names.index(t[2]))\n",
    "    tactics.append(tactics_names.index(t[3]))\n",
    "\n",
    "mbti_df['mind'] = mind\n",
    "mbti_df['energy'] = energy\n",
    "mbti_df['nature'] = nature\n",
    "mbti_df['tactics'] = tactics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "\n",
    "def translate_text(text):\n",
    "    result=\"\"\n",
    "    try:\n",
    "        for sentence in text.split(\".\"):\n",
    "            result=result+translator.translate(sentence,dest='ko').text\n",
    "    \n",
    "        print(result)\n",
    "        return result\n",
    "    except Exception:\n",
    "        return text\n",
    "\n",
    "def replace_text(text):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english')) # Load stop words\n",
    "    pers_types = ['INFP' ,'INFJ', 'INTP', 'INTJ', 'ENTP', 'ENFP', 'ISTP' ,'ISFP' ,'ENTJ', 'ISTJ','ENFJ', 'ISFJ' ,'ESTP', 'ESFP' ,'ESFJ' ,'ESTJ']\n",
    "    pers_types = [p.lower() for p in pers_types]  \n",
    "    try:\n",
    "        \n",
    "        text=re.sub('https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+',' ',text)\n",
    "        \n",
    "        text=re.sub('[^0-9a-z]',' ',text)\n",
    "        text=text.lower()    \n",
    "        text = \" \".join([word for word in text.split() if word not in stop_words]) # Remove stop words\n",
    "        #print(len(sentence))\n",
    "        \n",
    "        for p in pers_types:\n",
    "            text = re.sub(p, '', text)\n",
    "        #print(len(sentence))\n",
    "        \n",
    "        text = lemmatizer.lemmatize(text) # Lemmatize words\n",
    "    except:\n",
    "        ''''''    \n",
    "    return text    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti_df['posts']=mbti_df['posts'].apply(replace_text)\n",
    "# mbti_df['posts']=mbti_df['posts'].apply(translate_text)\n",
    "# mbti_df.to_csv('mbti_1_kor.csv')\n",
    "\n",
    "# mbti_df.to_csv('mbti_1_replace.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>mind</th>\n",
       "      <th>energy</th>\n",
       "      <th>nature</th>\n",
       "      <th>tactics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>moments sportscenter top ten plays pranks hat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>finding lack posts alarming ex boring position...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>ood one course say know blessing curse oes abs...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>ear enjoyed conversation day soteric gabbing n...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>ou fired hat another silly misconception hat a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>always think cats doms reason websites become ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>thread already exists someplace else heck dele...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>many questions things would take purple pill i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>conflicted right comes wanting children honest...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>long since personalitycafe although seem chang...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  mind  energy  \\\n",
       "0     INFJ   moments sportscenter top ten plays pranks hat...     1       0   \n",
       "1     ENTP  finding lack posts alarming ex boring position...     0       0   \n",
       "2     INTP  ood one course say know blessing curse oes abs...     1       0   \n",
       "3     INTJ  ear enjoyed conversation day soteric gabbing n...     1       0   \n",
       "4     ENTJ  ou fired hat another silly misconception hat a...     0       0   \n",
       "...    ...                                                ...   ...     ...   \n",
       "8670  ISFP  always think cats doms reason websites become ...     1       1   \n",
       "8671  ENFP  thread already exists someplace else heck dele...     0       0   \n",
       "8672  INTP  many questions things would take purple pill i...     1       0   \n",
       "8673  INFP  conflicted right comes wanting children honest...     1       0   \n",
       "8674  INFP  long since personalitycafe although seem chang...     1       0   \n",
       "\n",
       "      nature  tactics  \n",
       "0          0        0  \n",
       "1          1        1  \n",
       "2          1        1  \n",
       "3          1        0  \n",
       "4          1        0  \n",
       "...      ...      ...  \n",
       "8670       0        1  \n",
       "8671       0        1  \n",
       "8672       1        1  \n",
       "8673       0        1  \n",
       "8674       0        1  \n",
       "\n",
       "[8675 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "max_len=50000\n",
    "max_words=10000\n",
    "label_mind = mbti_df.mind\n",
    "label_energy = mbti_df.energy\n",
    "label_nature = mbti_df.nature\n",
    "label_tactics = mbti_df.tactics\n",
    "feature = mbti_df.posts\n",
    "\n",
    "tokenizer=tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(feature)\n",
    "\n",
    "feature=tokenizer.texts_to_sequences(feature)\n",
    "\n",
    "max_length=max([len(seq) for seq in feature])\n",
    "vocabulary_size=len(tokenizer.word_index)+1\n",
    "embedding_dim=100\n",
    "\n",
    "\n",
    "feature=tf.keras.preprocessing.sequence.pad_sequences(feature,maxlen=max_length)\n",
    "\n",
    "label_mind = np.array(label_mind)\n",
    "label_energy = np.array(label_energy)\n",
    "label_nature = np.array(label_nature)\n",
    "label_tactics = np.array(label_tactics)\n",
    "\n",
    "\n",
    "\n",
    "feature_train, feature_test, labelm_train, labelm_test = train_test_split (feature, label_mind, test_size =.3 , random_state= 42, stratify= label_mind)\n",
    "feature_train, feature_test, labele_train, labele_test = train_test_split (feature, label_energy, test_size =.3 , random_state= 42, stratify= label_energy)\n",
    "feature_train, feature_test, labeln_train, labeln_test = train_test_split (feature, label_nature, test_size =.3 , random_state= 42, stratify= label_nature)\n",
    "feature_train, feature_test, labelt_train, labelt_test = train_test_split (feature, label_tactics, test_size =.3 , random_state= 42, stratify= label_nature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createModel():\n",
    "  model = tf.keras.Sequential()\n",
    "  # model.add(hub_layer)\n",
    "  model.add(tf.keras.layers.Embedding(input_dim=vocabulary_size,output_dim=embedding_dim,input_length=max_length))\n",
    "  # model.add(tf.keras.layers.Embedding(vocab_len+1,embedding_dim,input_length=max_length))\n",
    "  model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dense(1,))\n",
    "\n",
    "  # model.summary()\n",
    "  model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(res, range, minima):\n",
    "  normalized_vals = []\n",
    "  for arr in res:\n",
    "    normalized_vals.append((arr[0] + abs(minima))/range)\n",
    "  return normalized_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,   181,   121,    32],\n",
       "       [    0,     0,     0, ...,    44,    44,   117],\n",
       "       [    0,     0,     0, ...,  1264, 58338, 58339],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  2609,   590,  1538],\n",
       "       [    0,     0,     0, ...,  1301,  1197,   115],\n",
       "       [    0,     0,     0, ...,    91,    56,    50]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature\n",
    "# feature_val = feature_train[3036:]\n",
    "# partial_feature_train = feature_train[:3036]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index\n",
    "import csv\n",
    "with open('word_index.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['word', 'index'])\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        writer.writerow([word, index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# m_val = labelm_train[3036:]\n",
    "# partial_m_train = labelm_train[:3036]\n",
    "\n",
    "# e_val = labele_train[3036:]\n",
    "# partial_e_train = labele_train[:3036]\n",
    "\n",
    "# n_val = labeln_train[3036:]\n",
    "# partial_n_train = labeln_train[:3036]\n",
    "\n",
    "# t_val = labelt_train[3036:]\n",
    "# partial_t_train = labelt_train[:3036]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_to_mind(float_results):\n",
    "    res = []\n",
    "    for num in float_results:\n",
    "        if(num < 0.5):\n",
    "            res.append(\"E\")\n",
    "        else:\n",
    "            res.append(\"I\")\n",
    "    return res\n",
    "\n",
    "\n",
    "def float_to_energy(float_results):\n",
    "    res = []\n",
    "    for num in float_results:\n",
    "        if(num < 0.5):\n",
    "            res.append(\"N\")\n",
    "        else:\n",
    "            res.append(\"S\")\n",
    "    return res\n",
    "\n",
    "\n",
    "def float_to_nature(float_results):\n",
    "    res = []\n",
    "    for num in float_results:\n",
    "        if(num < 0.5):\n",
    "            res.append(\"F\")\n",
    "        else:\n",
    "            res.append(\"T\")\n",
    "    return res   \n",
    "\n",
    "def float_to_tactics(float_results):\n",
    "    res = []\n",
    "    for num in float_results:\n",
    "        if(num < 0.5):\n",
    "            res.append(\"J\")\n",
    "        else:\n",
    "            res.append(\"P\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'Cast_19' defined at (most recent call last):\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\traitlets\\config\\application.py\", line 982, in launch_instance\n      app.start()\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\taegi\\AppData\\Local\\Temp\\ipykernel_23424\\1944590311.py\", line 2, in <module>\n      history = mind.fit(feature,\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\engine\\training.py\", line 1055, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\engine\\training.py\", line 1149, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 691, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\metrics\\accuracy_metrics.py\", line 395, in binary_accuracy\n      metrics_utils.binary_matches(y_true, y_pred, threshold), axis=-1\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 934, in binary_matches\n      return tf.cast(tf.equal(y_true, y_pred), backend.floatx())\nNode: 'Cast_19'\nOOM when allocating tensor with shape[512,907,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node Cast_19}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1173]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\taegi\\Desktop\\mp\\mbti model\\model copy.ipynb Cell 15\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/mbti%20model/model%20copy.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mind \u001b[39m=\u001b[39m createModel()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/mbti%20model/model%20copy.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m history \u001b[39m=\u001b[39m mind\u001b[39m.\u001b[39;49mfit(feature,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/mbti%20model/model%20copy.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                     label_mind,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/mbti%20model/model%20copy.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/mbti%20model/model%20copy.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/mbti%20model/model%20copy.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                      validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/mbti%20model/model%20copy.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                     )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/mbti%20model/model%20copy.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# tfjs.converters.save_keras_model(mind, \"mind\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'Cast_19' defined at (most recent call last):\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\traitlets\\config\\application.py\", line 982, in launch_instance\n      app.start()\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\taegi\\AppData\\Local\\Temp\\ipykernel_23424\\1944590311.py\", line 2, in <module>\n      history = mind.fit(feature,\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\engine\\training.py\", line 1055, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\engine\\training.py\", line 1149, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 691, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\metrics\\accuracy_metrics.py\", line 395, in binary_accuracy\n      metrics_utils.binary_matches(y_true, y_pred, threshold), axis=-1\n    File \"c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 934, in binary_matches\n      return tf.cast(tf.equal(y_true, y_pred), backend.floatx())\nNode: 'Cast_19'\nOOM when allocating tensor with shape[512,907,512] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node Cast_19}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_1173]"
     ]
    }
   ],
   "source": [
    "\n",
    "mind = createModel()\n",
    "history = mind.fit(feature,\n",
    "                    label_mind,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                     validation_split=0.2,\n",
    "                    )\n",
    "\n",
    "# tfjs.converters.save_keras_model(mind, \"mind\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "14/14 [==============================] - 32s 2s/step - loss: 1.1004 - accuracy: 0.8630 - val_loss: 0.7529 - val_accuracy: 0.8582\n",
      "Epoch 2/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.5457 - accuracy: 0.8630 - val_loss: 0.4603 - val_accuracy: 0.8582\n",
      "Epoch 3/40\n",
      "14/14 [==============================] - 35s 2s/step - loss: 0.4317 - accuracy: 0.8630 - val_loss: 0.4292 - val_accuracy: 0.8582\n",
      "Epoch 4/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.4125 - accuracy: 0.8630 - val_loss: 0.4161 - val_accuracy: 0.8582\n",
      "Epoch 5/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.4055 - accuracy: 0.8630 - val_loss: 0.4135 - val_accuracy: 0.8582\n",
      "Epoch 6/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.4037 - accuracy: 0.8630 - val_loss: 0.4123 - val_accuracy: 0.8582\n",
      "Epoch 7/40\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.4027 - accuracy: 0.8630 - val_loss: 0.4115 - val_accuracy: 0.8582\n",
      "Epoch 8/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.4020 - accuracy: 0.8630 - val_loss: 0.4111 - val_accuracy: 0.8582\n",
      "Epoch 9/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.4017 - accuracy: 0.8630 - val_loss: 0.4108 - val_accuracy: 0.8582\n",
      "Epoch 10/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.4014 - accuracy: 0.8630 - val_loss: 0.4105 - val_accuracy: 0.8582\n",
      "Epoch 11/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.4011 - accuracy: 0.8630 - val_loss: 0.4098 - val_accuracy: 0.8582\n",
      "Epoch 12/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.4006 - accuracy: 0.8630 - val_loss: 0.4097 - val_accuracy: 0.8582\n",
      "Epoch 13/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.4005 - accuracy: 0.8630 - val_loss: 0.4096 - val_accuracy: 0.8582\n",
      "Epoch 14/40\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.4004 - accuracy: 0.8630 - val_loss: 0.4094 - val_accuracy: 0.8582\n",
      "Epoch 15/40\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.4003 - accuracy: 0.8630 - val_loss: 0.4093 - val_accuracy: 0.8582\n",
      "Epoch 16/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.4002 - accuracy: 0.8630 - val_loss: 0.4092 - val_accuracy: 0.8582\n",
      "Epoch 17/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.4002 - accuracy: 0.8630 - val_loss: 0.4092 - val_accuracy: 0.8582\n",
      "Epoch 18/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.4001 - accuracy: 0.8630 - val_loss: 0.4091 - val_accuracy: 0.8582\n",
      "Epoch 19/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.4001 - accuracy: 0.8630 - val_loss: 0.4090 - val_accuracy: 0.8582\n",
      "Epoch 20/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.4000 - accuracy: 0.8630 - val_loss: 0.4090 - val_accuracy: 0.8582\n",
      "Epoch 21/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.4000 - accuracy: 0.8630 - val_loss: 0.4090 - val_accuracy: 0.8582\n",
      "Epoch 22/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.3999 - accuracy: 0.8630 - val_loss: 0.4089 - val_accuracy: 0.8582\n",
      "Epoch 23/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.3999 - accuracy: 0.8630 - val_loss: 0.4089 - val_accuracy: 0.8582\n",
      "Epoch 24/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.3999 - accuracy: 0.8630 - val_loss: 0.4089 - val_accuracy: 0.8582\n",
      "Epoch 25/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.3999 - accuracy: 0.8630 - val_loss: 0.4088 - val_accuracy: 0.8582\n",
      "Epoch 26/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.3998 - accuracy: 0.8630 - val_loss: 0.4088 - val_accuracy: 0.8582\n",
      "Epoch 27/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.3998 - accuracy: 0.8630 - val_loss: 0.4088 - val_accuracy: 0.8582\n",
      "Epoch 28/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.3998 - accuracy: 0.8630 - val_loss: 0.4088 - val_accuracy: 0.8582\n",
      "Epoch 29/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.3998 - accuracy: 0.8630 - val_loss: 0.4088 - val_accuracy: 0.8582\n",
      "Epoch 30/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.3998 - accuracy: 0.8630 - val_loss: 0.4087 - val_accuracy: 0.8582\n",
      "Epoch 31/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.3997 - accuracy: 0.8630 - val_loss: 0.4087 - val_accuracy: 0.8582\n",
      "Epoch 32/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.3998 - accuracy: 0.8630 - val_loss: 0.4087 - val_accuracy: 0.8582\n",
      "Epoch 33/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.3998 - accuracy: 0.8630 - val_loss: 0.4088 - val_accuracy: 0.8582\n",
      "Epoch 34/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.3997 - accuracy: 0.8630 - val_loss: 0.4087 - val_accuracy: 0.8582\n",
      "Epoch 35/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.3997 - accuracy: 0.8630 - val_loss: 0.4085 - val_accuracy: 0.8582\n",
      "Epoch 36/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.3997 - accuracy: 0.8630 - val_loss: 0.4085 - val_accuracy: 0.8582\n",
      "Epoch 37/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.3997 - accuracy: 0.8630 - val_loss: 0.4086 - val_accuracy: 0.8582\n",
      "Epoch 38/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.3996 - accuracy: 0.8630 - val_loss: 0.4085 - val_accuracy: 0.8582\n",
      "Epoch 39/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.3997 - accuracy: 0.8630 - val_loss: 0.4085 - val_accuracy: 0.8582\n",
      "Epoch 40/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.3997 - accuracy: 0.8630 - val_loss: 0.4086 - val_accuracy: 0.8582\n"
     ]
    }
   ],
   "source": [
    "energy = createModel()\n",
    "history = energy.fit(feature,\n",
    "                    label_energy,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_split=0.2,\n",
    "                   )\n",
    "# tfjs.converters.save_keras_model(energy, \"energy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 1.2320 - accuracy: 0.5427 - val_loss: 0.9398 - val_accuracy: 0.5349\n",
      "Epoch 2/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.8516 - accuracy: 0.5427 - val_loss: 0.7948 - val_accuracy: 0.5349\n",
      "Epoch 3/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.7604 - accuracy: 0.5426 - val_loss: 0.7454 - val_accuracy: 0.5343\n",
      "Epoch 4/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.7290 - accuracy: 0.5419 - val_loss: 0.7259 - val_accuracy: 0.5346\n",
      "Epoch 5/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.7161 - accuracy: 0.5425 - val_loss: 0.7167 - val_accuracy: 0.5349\n",
      "Epoch 6/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.7091 - accuracy: 0.5427 - val_loss: 0.7111 - val_accuracy: 0.5349\n",
      "Epoch 7/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.7045 - accuracy: 0.5427 - val_loss: 0.7075 - val_accuracy: 0.5349\n",
      "Epoch 8/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.7015 - accuracy: 0.5427 - val_loss: 0.7050 - val_accuracy: 0.5349\n",
      "Epoch 9/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6993 - accuracy: 0.5427 - val_loss: 0.7029 - val_accuracy: 0.5349\n",
      "Epoch 10/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6974 - accuracy: 0.5427 - val_loss: 0.7013 - val_accuracy: 0.5349\n",
      "Epoch 11/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6962 - accuracy: 0.5427 - val_loss: 0.7001 - val_accuracy: 0.5349\n",
      "Epoch 12/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6950 - accuracy: 0.5427 - val_loss: 0.6990 - val_accuracy: 0.5349\n",
      "Epoch 13/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6943 - accuracy: 0.5427 - val_loss: 0.6984 - val_accuracy: 0.5349\n",
      "Epoch 14/40\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.6936 - accuracy: 0.5427 - val_loss: 0.6977 - val_accuracy: 0.5349\n",
      "Epoch 15/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6931 - accuracy: 0.5427 - val_loss: 0.6973 - val_accuracy: 0.5349\n",
      "Epoch 16/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6927 - accuracy: 0.5427 - val_loss: 0.6971 - val_accuracy: 0.5349\n",
      "Epoch 17/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6924 - accuracy: 0.5427 - val_loss: 0.6967 - val_accuracy: 0.5349\n",
      "Epoch 18/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6922 - accuracy: 0.5427 - val_loss: 0.6965 - val_accuracy: 0.5349\n",
      "Epoch 19/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6920 - accuracy: 0.5427 - val_loss: 0.6962 - val_accuracy: 0.5349\n",
      "Epoch 20/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6917 - accuracy: 0.5427 - val_loss: 0.6962 - val_accuracy: 0.5349\n",
      "Epoch 21/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6916 - accuracy: 0.5427 - val_loss: 0.6960 - val_accuracy: 0.5349\n",
      "Epoch 22/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6914 - accuracy: 0.5427 - val_loss: 0.6957 - val_accuracy: 0.5349\n",
      "Epoch 23/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6913 - accuracy: 0.5427 - val_loss: 0.6956 - val_accuracy: 0.5349\n",
      "Epoch 24/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6912 - accuracy: 0.5427 - val_loss: 0.6956 - val_accuracy: 0.5349\n",
      "Epoch 25/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6911 - accuracy: 0.5427 - val_loss: 0.6956 - val_accuracy: 0.5349\n",
      "Epoch 26/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6909 - accuracy: 0.5427 - val_loss: 0.6953 - val_accuracy: 0.5349\n",
      "Epoch 27/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6910 - accuracy: 0.5427 - val_loss: 0.6952 - val_accuracy: 0.5349\n",
      "Epoch 28/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6908 - accuracy: 0.5427 - val_loss: 0.6952 - val_accuracy: 0.5349\n",
      "Epoch 29/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6907 - accuracy: 0.5427 - val_loss: 0.6951 - val_accuracy: 0.5349\n",
      "Epoch 30/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6907 - accuracy: 0.5427 - val_loss: 0.6949 - val_accuracy: 0.5349\n",
      "Epoch 31/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6906 - accuracy: 0.5427 - val_loss: 0.6951 - val_accuracy: 0.5349\n",
      "Epoch 32/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6905 - accuracy: 0.5427 - val_loss: 0.6948 - val_accuracy: 0.5349\n",
      "Epoch 33/40\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.6905 - accuracy: 0.5427 - val_loss: 0.6947 - val_accuracy: 0.5349\n",
      "Epoch 34/40\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.6904 - accuracy: 0.5427 - val_loss: 0.6948 - val_accuracy: 0.5349\n",
      "Epoch 35/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6904 - accuracy: 0.5427 - val_loss: 0.6947 - val_accuracy: 0.5349\n",
      "Epoch 36/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.6904 - accuracy: 0.5427 - val_loss: 0.6948 - val_accuracy: 0.5349\n",
      "Epoch 37/40\n",
      "14/14 [==============================] - 33s 2s/step - loss: 0.6903 - accuracy: 0.5427 - val_loss: 0.6946 - val_accuracy: 0.5349\n",
      "Epoch 38/40\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.6904 - accuracy: 0.5427 - val_loss: 0.6945 - val_accuracy: 0.5349\n",
      "Epoch 39/40\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.6902 - accuracy: 0.5427 - val_loss: 0.6945 - val_accuracy: 0.5349\n",
      "Epoch 40/40\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.6902 - accuracy: 0.5427 - val_loss: 0.6945 - val_accuracy: 0.5349\n"
     ]
    }
   ],
   "source": [
    "nature = createModel()\n",
    "history = nature.fit(feature,\n",
    "                    label_nature,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_split=0.2,\n",
    "                   )\n",
    "# tfjs.converters.save_keras_model(model, \"nature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "14/14 [==============================] - 33s 2s/step - loss: 8.1212 - accuracy: 0.3955 - val_loss: 7.0940 - val_accuracy: 0.3971\n",
      "Epoch 2/40\n",
      "14/14 [==============================] - 32s 2s/step - loss: 6.1324 - accuracy: 0.3955 - val_loss: 5.0575 - val_accuracy: 0.3971\n",
      "Epoch 3/40\n",
      "14/14 [==============================] - 32s 2s/step - loss: 2.9746 - accuracy: 0.3955 - val_loss: 1.7432 - val_accuracy: 0.3971\n",
      "Epoch 4/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 1.5738 - accuracy: 0.3955 - val_loss: 1.4371 - val_accuracy: 0.3971\n",
      "Epoch 5/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 1.3781 - accuracy: 0.3955 - val_loss: 1.3205 - val_accuracy: 0.3971\n",
      "Epoch 6/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 1.2830 - accuracy: 0.3955 - val_loss: 1.2443 - val_accuracy: 0.3971\n",
      "Epoch 7/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 1.2146 - accuracy: 0.3955 - val_loss: 1.1845 - val_accuracy: 0.3971\n",
      "Epoch 8/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 1.1491 - accuracy: 0.3956 - val_loss: 1.1200 - val_accuracy: 0.3972\n",
      "Epoch 9/40\n",
      "14/14 [==============================] - 32s 2s/step - loss: 1.0954 - accuracy: 0.3960 - val_loss: 1.0715 - val_accuracy: 0.3983\n",
      "Epoch 10/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 1.0482 - accuracy: 0.3973 - val_loss: 1.0249 - val_accuracy: 0.3997\n",
      "Epoch 11/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 1.0035 - accuracy: 0.3990 - val_loss: 0.9820 - val_accuracy: 0.4017\n",
      "Epoch 12/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.9615 - accuracy: 0.4009 - val_loss: 0.9440 - val_accuracy: 0.4033\n",
      "Epoch 13/40\n",
      "14/14 [==============================] - 38s 3s/step - loss: 0.9250 - accuracy: 0.4027 - val_loss: 0.9098 - val_accuracy: 0.4051\n",
      "Epoch 14/40\n",
      "14/14 [==============================] - 33s 2s/step - loss: 0.8920 - accuracy: 0.4040 - val_loss: 0.8782 - val_accuracy: 0.4061\n",
      "Epoch 15/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.8614 - accuracy: 0.4063 - val_loss: 0.8499 - val_accuracy: 0.4085\n",
      "Epoch 16/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.8341 - accuracy: 0.4074 - val_loss: 0.8243 - val_accuracy: 0.4094\n",
      "Epoch 17/40\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.8098 - accuracy: 0.4088 - val_loss: 0.8016 - val_accuracy: 0.4116\n",
      "Epoch 18/40\n",
      "14/14 [==============================] - 40s 3s/step - loss: 0.7885 - accuracy: 0.4116 - val_loss: 0.7820 - val_accuracy: 0.4158\n",
      "Epoch 19/40\n",
      "14/14 [==============================] - 41s 3s/step - loss: 0.7702 - accuracy: 0.4570 - val_loss: 0.7653 - val_accuracy: 0.4884\n",
      "Epoch 20/40\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.7547 - accuracy: 0.4932 - val_loss: 0.7516 - val_accuracy: 0.4973\n",
      "Epoch 21/40\n",
      "14/14 [==============================] - 37s 3s/step - loss: 0.7420 - accuracy: 0.5031 - val_loss: 0.7403 - val_accuracy: 0.5075\n",
      "Epoch 22/40\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.7315 - accuracy: 0.5134 - val_loss: 0.7313 - val_accuracy: 0.5162\n",
      "Epoch 23/40\n",
      "14/14 [==============================] - 35s 2s/step - loss: 0.7233 - accuracy: 0.5215 - val_loss: 0.7240 - val_accuracy: 0.5249\n",
      "Epoch 24/40\n",
      "14/14 [==============================] - 33s 2s/step - loss: 0.7167 - accuracy: 0.5298 - val_loss: 0.7182 - val_accuracy: 0.5326\n",
      "Epoch 25/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.7115 - accuracy: 0.5376 - val_loss: 0.7137 - val_accuracy: 0.5402\n",
      "Epoch 26/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.7072 - accuracy: 0.5447 - val_loss: 0.7099 - val_accuracy: 0.5457\n",
      "Epoch 27/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.7037 - accuracy: 0.5503 - val_loss: 0.7067 - val_accuracy: 0.5512\n",
      "Epoch 28/40\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.7007 - accuracy: 0.5545 - val_loss: 0.7039 - val_accuracy: 0.5550\n",
      "Epoch 29/40\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.6981 - accuracy: 0.5584 - val_loss: 0.7015 - val_accuracy: 0.5581\n",
      "Epoch 30/40\n",
      "14/14 [==============================] - 33s 2s/step - loss: 0.6958 - accuracy: 0.5619 - val_loss: 0.6993 - val_accuracy: 0.5615\n",
      "Epoch 31/40\n",
      "14/14 [==============================] - 35s 2s/step - loss: 0.6938 - accuracy: 0.5649 - val_loss: 0.6975 - val_accuracy: 0.5655\n",
      "Epoch 32/40\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.6920 - accuracy: 0.5685 - val_loss: 0.6958 - val_accuracy: 0.5673\n",
      "Epoch 33/40\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.6904 - accuracy: 0.5706 - val_loss: 0.6943 - val_accuracy: 0.5707\n",
      "Epoch 34/40\n",
      "14/14 [==============================] - 33s 2s/step - loss: 0.6889 - accuracy: 0.5737 - val_loss: 0.6929 - val_accuracy: 0.5719\n",
      "Epoch 35/40\n",
      "14/14 [==============================] - 33s 2s/step - loss: 0.6877 - accuracy: 0.5749 - val_loss: 0.6917 - val_accuracy: 0.5734\n",
      "Epoch 36/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.6865 - accuracy: 0.5765 - val_loss: 0.6906 - val_accuracy: 0.5746\n",
      "Epoch 37/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.6855 - accuracy: 0.5778 - val_loss: 0.6897 - val_accuracy: 0.5769\n",
      "Epoch 38/40\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.6845 - accuracy: 0.5801 - val_loss: 0.6888 - val_accuracy: 0.5780\n",
      "Epoch 39/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.6837 - accuracy: 0.5812 - val_loss: 0.6879 - val_accuracy: 0.5791\n",
      "Epoch 40/40\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.6829 - accuracy: 0.5823 - val_loss: 0.6872 - val_accuracy: 0.5801\n"
     ]
    }
   ],
   "source": [
    "tactics = createModel()\n",
    "history = tactics.fit(feature,\n",
    "                    label_tactics,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_split=0.2,\n",
    "                   )\n",
    "#tfjs.converters.save_keras_model(model, \"tactics\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\taegi\\Desktop\\mp\\mbti model\\model copy.ipynb Cell 19\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/mbti%20model/model%20copy.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Mind\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/mbti%20model/model%20copy.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m res1 \u001b[39m=\u001b[39m mind\u001b[39m.\u001b[39mpredict(feature_train)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/mbti%20model/model%20copy.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m m_minima \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m((\u001b[39mmin\u001b[39;49m(res1))[\u001b[39m0\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/mbti%20model/model%20copy.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m m_maxima \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m((\u001b[39mmax\u001b[39m(res1))[\u001b[39m0\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/mbti%20model/model%20copy.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m m_range \u001b[39m=\u001b[39m m_maxima\u001b[39m-\u001b[39mm_minima\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mind\n",
    "res1 = mind.predict(feature_train)\n",
    "m_minima = float((min(res1))[0])\n",
    "m_maxima = float((max(res1))[0])\n",
    "m_range = m_maxima-m_minima\n",
    "\n",
    "# Energy\n",
    "res1 = energy.predict(feature_train)\n",
    "e_minima = float((min(res1))[0])\n",
    "e_maxima = float((max(res1))[0])\n",
    "e_range = e_maxima-e_minima\n",
    "\n",
    "# Nature\n",
    "res1 = nature.predict(feature_train)\n",
    "n_minima = float((min(res1))[0])\n",
    "n_maxima = float((max(res1))[0])\n",
    "n_range = n_maxima-n_minima\n",
    "\n",
    "# Tactics\n",
    "res1 = tactics.predict(feature_train)\n",
    "t_minima = float((min(res1))[0])\n",
    "t_maxima = float((max(res1))[0])\n",
    "t_range = t_maxima-t_minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(input_string):\n",
    "  input_arr = []\n",
    "  input_arr.append(input_string)\n",
    "\n",
    "  # Mind\n",
    "  results = mind.predict(input_arr)\n",
    "  mind_res = (float_to_mind(normalize(results, m_range, m_minima)))[0]\n",
    "\n",
    "  # Energy\n",
    "  results = energy.predict(input_arr)\n",
    "  energy_res = (float_to_energy(normalize(results, e_range, e_minima)))[0]\n",
    "  \n",
    "  # Nature\n",
    "  results = nature.predict(input_arr)\n",
    "  nature_res = (float_to_nature(normalize(results, n_range, n_minima)))[0]\n",
    "\n",
    "  # Tactics\n",
    "  results = tactics.predict(input_arr)\n",
    "  tactics_res = (float_to_tactics(normalize(results, t_range, t_minima)))[0]\n",
    "\n",
    "  return mind_res + energy_res + nature_res + tactics_res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict(input())\n",
    "print(results)\n",
    "print(d[results])\n",
    "\n",
    "# mind.save('mind.h5')\n",
    "# energy.save('energy.h5')\n",
    "# nature.save('nature.h5')\n",
    "# tactics.save('tactics.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./energys\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./energys\\assets\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./minds\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./minds\\assets\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./natures\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./natures\\assets\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./tacticss\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./tacticss\\assets\n"
     ]
    }
   ],
   "source": [
    "# energy.save('./energys', save_format='tf')\n",
    "\n",
    "# mind.save('./minds', save_format='tf')\n",
    "# nature.save('./natures', save_format='tf')\n",
    "# tactics.save('./tacticss', save_format='tf')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
