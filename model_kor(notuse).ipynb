{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'INTJ':'You are thoughtful, rational, quick-witted and independent. However, sometimes you are known to be overly critical, and have a combative side to yourself.', 'INTP':'You are unique, creative, inventive and imaginative. However, sometimes you are known to be a bit insensitive and impatient with others.', 'ENTJ':'You are determined, charismatic, confident and authoritative. However, sometimes you are known to  be intolerant of other people\\'s weaknesses, and slightly arrogant.', 'ENTP':'You are audacious, bold, playful and rebellious. However, sometimes you can find it difficult to focus, and dislike talking about practical matters.', 'INFJ':'You are creative, insightful, passionate and have strong morals. However, sometimes you are a bit of a perfectionist, and find it reluctant to open up to other people.','INFP':'You are empathetic, generous, creative and passionate. However, sometimes your goals are a bit unrealistic and you tend to lack focus sometimes.', 'ENFJ':'You are passionate, reliable, charismatic and very receptive. However, sometimes you can be overly empathetic and condescending toward other people.', 'ENFP' : 'You are enthusiastic, festive, good-natured and excellent at communicating. However, you sometimes focus on being a people pleaser and disorganized.', 'ISTJ': 'You are very responsible, strong-willed, calm and enforce order. However, you are known to be stubborn and are somewhat judgemental sometimes', 'ISFJ': 'You are reliable, observant, enthusiastic and supportive. However, you are known to be overly humble and tend to take things personally', 'ESTJ' : 'You are dedicated, strong-willed, loyal and reliable. However, you find it difficult to relax, or share what you\\'re feeling with other people.', 'ESFJ': 'You are very loyal, sensitive to other people\\'s feelings, and have strong practical skills. However, you are sometimes worried about your social status and tend to be vulnerable to criticism.', 'ISTP': 'You are spotaneous, rational, optimistic and know how to prioritize things. However, you are known to be stubborn and get bored very easily.',  'ISFP' : 'You are charming, imaginative, passionate and sensitive to others. However, you are fiercely independent and get stressed out pretty easily.', 'ESTP': 'You are perceptive, direct, bold and rational. However, you tend to be defiant and may sometimes miss the bigger picture in favor of smaller victories.', 'ESFP' : 'You are observant, practical, have excellent people skills and are fond of showmanship. However, you are very sensitive and sometimes avoid conflict entirely.'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti_df = pd.read_csv(\"mbti_1_kor.csv\")\n",
    "\n",
    "mbti_df['posts'].fillna('')\n",
    "\n",
    "\n",
    "# mind_names = [\"E\" , \"I\"]\n",
    "# mind = []  # E or I\n",
    "\n",
    "# energy_names = [\"N\",  \"S\"]\n",
    "# energy = [] # N or S\n",
    "\n",
    "# nature_names = [\"F\", \"T\"]\n",
    "# nature = [] # F or T\n",
    "\n",
    "# tactics_names = [\"J\", \"P\"]\n",
    "\n",
    "# tactics = [] # J OR P\n",
    "\n",
    "# for t in mbti_df.type:\n",
    "#   mind.append(mind_names.index(t[0]))\n",
    "#   energy.append(energy_names.index(t[1]))\n",
    "#   nature.append(nature_names.index(t[2]))\n",
    "#   tactics.append(tactics_names.index(t[3]))\n",
    "\n",
    "# mbti_df['mind'] = mind\n",
    "# mbti_df['energy'] = energy\n",
    "# mbti_df['nature'] = nature\n",
    "# mbti_df['tactics'] = tactics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "\n",
    "def translate_text(text):\n",
    "    result=\"\"\n",
    "    try:\n",
    "        for sentence in text.split(\".\"):\n",
    "            result=result+translator.translate(sentence,dest='ko').text\n",
    "    \n",
    "        print(result)\n",
    "        return result\n",
    "    except Exception:\n",
    "        return text\n",
    "\n",
    "def replace_text(text):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english')) # Load stop words\n",
    "    pers_types = ['INFP' ,'INFJ', 'INTP', 'INTJ', 'ENTP', 'ENFP', 'ISTP' ,'ISFP' ,'ENTJ', 'ISTJ','ENFJ', 'ISFJ' ,'ESTP', 'ESFP' ,'ESFJ' ,'ESTJ']\n",
    "    pers_types = [p.lower() for p in pers_types]  \n",
    "    try:\n",
    "        \n",
    "        text=re.sub('https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+',' ',text)\n",
    "        \n",
    "        text=re.sub('[^0-9a-z]',' ',text)\n",
    "        text=text.lower()    \n",
    "        text = \" \".join([word for word in text.split() if word not in stop_words]) # Remove stop words\n",
    "        #print(len(sentence))\n",
    "        \n",
    "        for p in pers_types:\n",
    "            text = re.sub(p, '', text)\n",
    "        #print(len(sentence))\n",
    "        \n",
    "        text = lemmatizer.lemmatize(text) # Lemmatize words\n",
    "    except:\n",
    "        ''''''    \n",
    "    return text    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti_df['posts']=mbti_df['posts'].apply(replace_text)\n",
    "# mbti_df['posts']=mbti_df['posts'].apply(translate_text)\n",
    "# mbti_df.to_csv('mbti_1_kor.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'toString'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\taegi\\Desktop\\mp\\model.ipynb Cell 6\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/model.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mbti_df[\u001b[39m'\u001b[39;49m\u001b[39mposts\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mtoString()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'toString'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "label_mind = mbti_df.mind\n",
    "label_energy = mbti_df.energy\n",
    "label_nature = mbti_df.nature\n",
    "label_tactics = mbti_df.tactics\n",
    "feature = mbti_df.posts\n",
    "\n",
    "feature_train, feature_test, labelm_train, labelm_test = train_test_split (feature, label_mind, test_size =.3 , random_state= 42, stratify= label_mind)\n",
    "feature_train, feature_test, labele_train, labele_test = train_test_split (feature, label_energy, test_size =.3 , random_state= 42, stratify= label_energy)\n",
    "feature_train, feature_test, labeln_train, labeln_test = train_test_split (feature, label_nature, test_size =.3 , random_state= 42, stratify= label_nature)\n",
    "feature_train, feature_test, labelt_train, labelt_test = train_test_split (feature, label_tactics, test_size =.3 , random_state= 42, stratify= label_nature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "embedding_dim = 300\n",
    "max_length = 900\n",
    "vocab_len=19999\n",
    "def createModel():\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(hub_layer)\n",
    "  # model.add(tf.keras.layers.Embedding(vocab_len+1,embedding_dim,input_length=max_length))\n",
    "  model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "  model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "  model.summary()\n",
    "  model.compile(optimizer='adam',\n",
    "                loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(res, range, minima):\n",
    "  normalized_vals = []\n",
    "  for arr in res:\n",
    "    normalized_vals.append((arr[0] + abs(minima))/range)\n",
    "  return normalized_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taegi\\AppData\\Local\\Temp\\ipykernel_25016\\529373074.py:1: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  feature_val = feature_train[3036:]\n",
      "C:\\Users\\taegi\\AppData\\Local\\Temp\\ipykernel_25016\\529373074.py:2: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  partial_feature_train = feature_train[:3036]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_val = feature_train[3036:]\n",
    "partial_feature_train = feature_train[:3036]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taegi\\AppData\\Local\\Temp\\ipykernel_25016\\2977004095.py:1: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  m_val = labelm_train[3036:]\n",
      "C:\\Users\\taegi\\AppData\\Local\\Temp\\ipykernel_25016\\2977004095.py:2: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  partial_m_train = labelm_train[:3036]\n",
      "C:\\Users\\taegi\\AppData\\Local\\Temp\\ipykernel_25016\\2977004095.py:4: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  e_val = labele_train[3036:]\n",
      "C:\\Users\\taegi\\AppData\\Local\\Temp\\ipykernel_25016\\2977004095.py:5: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  partial_e_train = labele_train[:3036]\n",
      "C:\\Users\\taegi\\AppData\\Local\\Temp\\ipykernel_25016\\2977004095.py:7: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  n_val = labeln_train[3036:]\n",
      "C:\\Users\\taegi\\AppData\\Local\\Temp\\ipykernel_25016\\2977004095.py:8: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  partial_n_train = labeln_train[:3036]\n",
      "C:\\Users\\taegi\\AppData\\Local\\Temp\\ipykernel_25016\\2977004095.py:10: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  t_val = labelt_train[3036:]\n",
      "C:\\Users\\taegi\\AppData\\Local\\Temp\\ipykernel_25016\\2977004095.py:11: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  partial_t_train = labelt_train[:3036]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m_val = labelm_train[3036:]\n",
    "partial_m_train = labelm_train[:3036]\n",
    "\n",
    "e_val = labele_train[3036:]\n",
    "partial_e_train = labele_train[:3036]\n",
    "\n",
    "n_val = labeln_train[3036:]\n",
    "partial_n_train = labeln_train[:3036]\n",
    "\n",
    "t_val = labelt_train[3036:]\n",
    "partial_t_train = labelt_train[:3036]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_to_mind(float_results):\n",
    "    res = []\n",
    "    for num in float_results:\n",
    "        if(num < 0.5):\n",
    "            res.append(\"E\")\n",
    "        else:\n",
    "            res.append(\"I\")\n",
    "    return res\n",
    "\n",
    "\n",
    "def float_to_energy(float_results):\n",
    "    res = []\n",
    "    for num in float_results:\n",
    "        if(num < 0.5):\n",
    "            res.append(\"N\")\n",
    "        else:\n",
    "            res.append(\"S\")\n",
    "    return res\n",
    "\n",
    "\n",
    "def float_to_nature(float_results):\n",
    "    res = []\n",
    "    for num in float_results:\n",
    "        if(num < 0.5):\n",
    "            res.append(\"F\")\n",
    "        else:\n",
    "            res.append(\"T\")\n",
    "    return res   \n",
    "\n",
    "def float_to_tactics(float_results):\n",
    "    res = []\n",
    "    for num in float_results:\n",
    "        if(num < 0.5):\n",
    "            res.append(\"J\")\n",
    "        else:\n",
    "            res.append(\"P\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 50)                48190600  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                816       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,191,433\n",
      "Trainable params: 48,191,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type float).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\taegi\\Desktop\\mp\\model.ipynb Cell 15\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/model.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mind \u001b[39m=\u001b[39m createModel()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/model.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m history \u001b[39m=\u001b[39m mind\u001b[39m.\u001b[39;49mfit(partial_feature_train,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/model.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                     partial_m_train,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/model.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/model.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/model.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(feature_val, m_val),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/model.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/model.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# tfjs.converters.save_keras_model(mind, \"mind\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    102\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type float)."
     ]
    }
   ],
   "source": [
    "\n",
    "mind = createModel()\n",
    "history = mind.fit(partial_feature_train,\n",
    "                    partial_m_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(feature_val, m_val),\n",
    "                    verbose=0)\n",
    "\n",
    "# tfjs.converters.save_keras_model(mind, \"mind\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 50)                48190600  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                816       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,191,433\n",
      "Trainable params: 48,191,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "energy = createModel()\n",
    "history = energy.fit(partial_feature_train,\n",
    "                    partial_e_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(feature_val, e_val),\n",
    "                    verbose=0)\n",
    "# tfjs.converters.save_keras_model(energy, \"energy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 50)                48190600  \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                816       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,191,433\n",
      "Trainable params: 48,191,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nature = createModel()\n",
    "history = nature.fit(partial_feature_train,\n",
    "                    partial_n_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(feature_val, n_val),\n",
    "                    verbose=0)\n",
    "# tfjs.converters.save_keras_model(model, \"nature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 50)                48190600  \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                816       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,191,433\n",
      "Trainable params: 48,191,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tactics = createModel()\n",
    "history = tactics.fit(partial_feature_train,\n",
    "                    partial_t_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(feature_val, t_val),\n",
    "                    verbose=0)\n",
    "#tfjs.converters.save_keras_model(model, \"tactics\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 10s 53ms/step\n",
      "190/190 [==============================] - 9s 48ms/step\n",
      "190/190 [==============================] - 9s 47ms/step\n",
      "190/190 [==============================] - 9s 46ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mind\n",
    "res1 = mind.predict(feature_train)\n",
    "m_minima = float((min(res1))[0])\n",
    "m_maxima = float((max(res1))[0])\n",
    "m_range = m_maxima-m_minima\n",
    "\n",
    "# Energy\n",
    "res1 = energy.predict(feature_train)\n",
    "e_minima = float((min(res1))[0])\n",
    "e_maxima = float((max(res1))[0])\n",
    "e_range = e_maxima-e_minima\n",
    "\n",
    "# Nature\n",
    "res1 = nature.predict(feature_train)\n",
    "n_minima = float((min(res1))[0])\n",
    "n_maxima = float((max(res1))[0])\n",
    "n_range = n_maxima-n_minima\n",
    "\n",
    "# Tactics\n",
    "res1 = tactics.predict(feature_train)\n",
    "t_minima = float((min(res1))[0])\n",
    "t_maxima = float((max(res1))[0])\n",
    "t_range = t_maxima-t_minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(input_string):\n",
    "  input_arr = []\n",
    "  input_arr.append(input_string)\n",
    "\n",
    "  # Mind\n",
    "  results = mind.predict(input_arr)\n",
    "  mind_res = (float_to_mind(normalize(results, m_range, m_minima)))[0]\n",
    "\n",
    "  # Energy\n",
    "  results = energy.predict(input_arr)\n",
    "  energy_res = (float_to_energy(normalize(results, e_range, e_minima)))[0]\n",
    "  \n",
    "  # Nature\n",
    "  results = nature.predict(input_arr)\n",
    "  nature_res = (float_to_nature(normalize(results, n_range, n_minima)))[0]\n",
    "\n",
    "  # Tactics\n",
    "  results = tactics.predict(input_arr)\n",
    "  tactics_res = (float_to_tactics(normalize(results, t_range, t_minima)))[0]\n",
    "\n",
    "  return mind_res + energy_res + nature_res + tactics_res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "WARNING:tensorflow:5 out of the last 194 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001BA84046EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 194 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001BA84046EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 126ms/step\n",
      "ESTJ\n",
      "You are dedicated, strong-willed, loyal and reliable. However, you find it difficult to relax, or share what you're feeling with other people.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\taegi\\AppData\\Local\\Temp\\tmpwv4vwy28\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\taegi\\AppData\\Local\\Temp\\tmpwv4vwy28\\assets\n"
     ]
    },
    {
     "ename": "ConverterError",
     "evalue": "c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150:0: error: 'tf.StringSplit' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\nc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150:0: error: 'tf.StringToHashBucketFast' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\nc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150:0: error: 'tf.SparseFillEmptyRows' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\nc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150:0: error: 'tf.SparseSegmentSqrtN' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\nc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150:0: note: Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: failed while converting: 'main': \nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \nTF Select ops: SparseFillEmptyRows, SparseSegmentSqrtN, StringSplit, StringToHashBucketFast\nDetails:\n\ttf.SparseFillEmptyRows(tensor<?x2xi64>, tensor<*xi64>, tensor<2xi64>, tensor<*xi64>) -> (tensor<?x2xi64>, tensor<?xi64>, tensor<?xi1>, tensor<?xi64>) : {device = \"\"}\n\ttf.SparseSegmentSqrtN(tensor<?x50xf32>, tensor<?xi32>, tensor<?xi32>) -> (tensor<?x50xf32>) : {device = \"\"}\n\ttf.StringSplit(tensor<?x!tf_type.string>, tensor<!tf_type.string>) -> (tensor<?x2xi64>, tensor<?x!tf_type.string>, tensor<2xi64>) : {device = \"\", skip_empty = true}\n\ttf.StringToHashBucketFast(tensor<?x!tf_type.string>) -> (tensor<?xi64>) : {device = \"\", num_buckets = 3060 : i64}\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\taegi\\Desktop\\mp\\test1.ipynb Cell 22\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/test1.ipynb#X30sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m nature_converter\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mlite\u001b[39m.\u001b[39mTFLiteConverter\u001b[39m.\u001b[39mfrom_keras_model(nature)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/test1.ipynb#X30sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m tactics_converter\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mlite\u001b[39m.\u001b[39mTFLiteConverter\u001b[39m.\u001b[39mfrom_keras_model(tactics)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/test1.ipynb#X30sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m mind_model\u001b[39m=\u001b[39mmind_converter\u001b[39m.\u001b[39;49mconvert()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/test1.ipynb#X30sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m energy_model\u001b[39m=\u001b[39menergy_converter\u001b[39m.\u001b[39mconvert()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/taegi/Desktop/mp/test1.ipynb#X30sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m nature_model\u001b[39m=\u001b[39mnature_converter\u001b[39m.\u001b[39mconvert()\n",
      "File \u001b[1;32mc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:962\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(convert_func)\n\u001b[0;32m    960\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    961\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 962\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_and_export_metrics(convert_func, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:940\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[1;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_conversion_params_metric()\n\u001b[0;32m    939\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mprocess_time()\n\u001b[1;32m--> 940\u001b[0m result \u001b[39m=\u001b[39m convert_func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    941\u001b[0m elapsed_time_ms \u001b[39m=\u001b[39m (time\u001b[39m.\u001b[39mprocess_time() \u001b[39m-\u001b[39m start_time) \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[0;32m    942\u001b[0m \u001b[39mif\u001b[39;00m result:\n",
      "File \u001b[1;32mc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1373\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2.convert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1360\u001b[0m \u001b[39m@_export_metrics\u001b[39m\n\u001b[0;32m   1361\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1362\u001b[0m   \u001b[39m\"\"\"Converts a keras model based on instance variables.\u001b[39;00m\n\u001b[0;32m   1363\u001b[0m \n\u001b[0;32m   1364\u001b[0m \u001b[39m  Returns:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1371\u001b[0m \u001b[39m      Invalid quantization parameters.\u001b[39;00m\n\u001b[0;32m   1372\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1373\u001b[0m   saved_model_convert_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_as_saved_model()\n\u001b[0;32m   1374\u001b[0m   \u001b[39mif\u001b[39;00m saved_model_convert_result:\n\u001b[0;32m   1375\u001b[0m     \u001b[39mreturn\u001b[39;00m saved_model_convert_result\n",
      "File \u001b[1;32mc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1355\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2._convert_as_saved_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1352\u001b[0m   graph_def, input_tensors, output_tensors \u001b[39m=\u001b[39m (\n\u001b[0;32m   1353\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_keras_to_saved_model(temp_dir))\n\u001b[0;32m   1354\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msaved_model_dir:\n\u001b[1;32m-> 1355\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(TFLiteKerasModelConverterV2,\n\u001b[0;32m   1356\u001b[0m                  \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mconvert(graph_def, input_tensors, output_tensors)\n\u001b[0;32m   1357\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1358\u001b[0m   shutil\u001b[39m.\u001b[39mrmtree(temp_dir, \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1166\u001b[0m, in \u001b[0;36mTFLiteConverterBaseV2.convert\u001b[1;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[0;32m   1161\u001b[0m   logging\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mUsing new converter: If you encounter a problem \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1162\u001b[0m                \u001b[39m\"\u001b[39m\u001b[39mplease file a bug. You can opt-out \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1163\u001b[0m                \u001b[39m\"\u001b[39m\u001b[39mby setting experimental_new_converter=False\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1165\u001b[0m \u001b[39m# Converts model.\u001b[39;00m\n\u001b[1;32m-> 1166\u001b[0m result \u001b[39m=\u001b[39m _convert_graphdef(\n\u001b[0;32m   1167\u001b[0m     input_data\u001b[39m=\u001b[39;49mgraph_def,\n\u001b[0;32m   1168\u001b[0m     input_tensors\u001b[39m=\u001b[39;49minput_tensors,\n\u001b[0;32m   1169\u001b[0m     output_tensors\u001b[39m=\u001b[39;49moutput_tensors,\n\u001b[0;32m   1170\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconverter_kwargs)\n\u001b[0;32m   1172\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimize_tflite_model(\n\u001b[0;32m   1173\u001b[0m     result, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_quant_mode, quant_io\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_new_quantizer)\n",
      "File \u001b[1;32mc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:212\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     report_error_message(\u001b[39mstr\u001b[39m(converter_error))\n\u001b[1;32m--> 212\u001b[0m   \u001b[39mraise\u001b[39;00m converter_error \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m  \u001b[39m# Re-throws the exception.\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[0;32m    214\u001b[0m   report_error_message(\u001b[39mstr\u001b[39m(error))\n",
      "File \u001b[1;32mc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    204\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    206\u001b[0m   \u001b[39mexcept\u001b[39;00m ConverterError \u001b[39mas\u001b[39;00m converter_error:\n\u001b[0;32m    207\u001b[0m     \u001b[39mif\u001b[39;00m converter_error\u001b[39m.\u001b[39merrors:\n",
      "File \u001b[1;32mc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:817\u001b[0m, in \u001b[0;36mconvert_graphdef\u001b[1;34m(input_data, input_tensors, output_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    814\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    815\u001b[0m     model_flags\u001b[39m.\u001b[39moutput_arrays\u001b[39m.\u001b[39mappend(util\u001b[39m.\u001b[39mget_tensor_name(output_tensor))\n\u001b[1;32m--> 817\u001b[0m data \u001b[39m=\u001b[39m convert(\n\u001b[0;32m    818\u001b[0m     model_flags\u001b[39m.\u001b[39;49mSerializeToString(),\n\u001b[0;32m    819\u001b[0m     conversion_flags\u001b[39m.\u001b[39;49mSerializeToString(),\n\u001b[0;32m    820\u001b[0m     input_data\u001b[39m.\u001b[39;49mSerializeToString(),\n\u001b[0;32m    821\u001b[0m     debug_info_str\u001b[39m=\u001b[39;49mdebug_info\u001b[39m.\u001b[39;49mSerializeToString() \u001b[39mif\u001b[39;49;00m debug_info \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    822\u001b[0m     enable_mlir_converter\u001b[39m=\u001b[39;49menable_mlir_converter)\n\u001b[0;32m    823\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:322\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(model_flags_str, conversion_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[39mfor\u001b[39;00m error_data \u001b[39min\u001b[39;00m _metrics_wrapper\u001b[39m.\u001b[39mretrieve_collected_errors():\n\u001b[0;32m    321\u001b[0m       converter_error\u001b[39m.\u001b[39mappend_error(error_data)\n\u001b[1;32m--> 322\u001b[0m     \u001b[39mraise\u001b[39;00m converter_error\n\u001b[0;32m    324\u001b[0m \u001b[39mreturn\u001b[39;00m _run_deprecated_conversion_binary(model_flags_str,\n\u001b[0;32m    325\u001b[0m                                          conversion_flags_str, input_data_str,\n\u001b[0;32m    326\u001b[0m                                          debug_info_str)\n",
      "\u001b[1;31mConverterError\u001b[0m: c:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150:0: error: 'tf.StringSplit' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\nc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150:0: error: 'tf.StringToHashBucketFast' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\nc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150:0: error: 'tf.SparseFillEmptyRows' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\nc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150:0: note: Error code: ERROR_NEEDS_FLEX_OPS\nc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150:0: error: 'tf.SparseSegmentSqrtN' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\nc:\\Users\\taegi\\anaconda3\\envs\\env38\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150:0: note: Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: failed while converting: 'main': \nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \nTF Select ops: SparseFillEmptyRows, SparseSegmentSqrtN, StringSplit, StringToHashBucketFast\nDetails:\n\ttf.SparseFillEmptyRows(tensor<?x2xi64>, tensor<*xi64>, tensor<2xi64>, tensor<*xi64>) -> (tensor<?x2xi64>, tensor<?xi64>, tensor<?xi1>, tensor<?xi64>) : {device = \"\"}\n\ttf.SparseSegmentSqrtN(tensor<?x50xf32>, tensor<?xi32>, tensor<?xi32>) -> (tensor<?x50xf32>) : {device = \"\"}\n\ttf.StringSplit(tensor<?x!tf_type.string>, tensor<!tf_type.string>) -> (tensor<?x2xi64>, tensor<?x!tf_type.string>, tensor<2xi64>) : {device = \"\", skip_empty = true}\n\ttf.StringToHashBucketFast(tensor<?x!tf_type.string>) -> (tensor<?xi64>) : {device = \"\", num_buckets = 3060 : i64}\n\n"
     ]
    }
   ],
   "source": [
    "results = predict(input())\n",
    "print(results)\n",
    "print(d[results])\n",
    "\n",
    "mind.save('mind.h5')\n",
    "energy.save('energy.h5')\n",
    "nature.save('nature.h5')\n",
    "tactics.save('tactics.h5')\n",
    "\n",
    "mind_converter=tf.lite.TFLiteConverter.from_keras_model(mind)\n",
    "energy_converter=tf.lite.TFLiteConverter.from_keras_model(energy)\n",
    "nature_converter=tf.lite.TFLiteConverter.from_keras_model(nature)\n",
    "tactics_converter=tf.lite.TFLiteConverter.from_keras_model(tactics)\n",
    "\n",
    "\n",
    "\n",
    "mind_model=mind_converter.convert()\n",
    "energy_model=energy_converter.convert()\n",
    "nature_model=nature_converter.convert()\n",
    "tactics_model=tactics_converter.convert()\n",
    "\n",
    "\n",
    "\n",
    "with open('mind_model.tflite', 'wb') as f:\n",
    "    f.write(mind_model)\n",
    "with open('energy_model.tflite', 'wb') as f:\n",
    "    f.write(energy_model)\n",
    "with open('nature_model.tflite', 'wb') as f:\n",
    "    f.write(nature_model)\n",
    "with open('tactics_model.tflite', 'wb') as f:\n",
    "    f.write(tactics_model)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
